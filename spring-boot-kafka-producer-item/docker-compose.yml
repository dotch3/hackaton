version: '3.6'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2

  kafka:
    image: confluentinc/cp-kafka:5.2.1
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://54.163.66.128:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

# create topic:
# docker-compose exec kafka  kafka-topics --create --topic item-cadastrado --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:2181
# Check topic
# docker-compose exec kafka  kafka-topics --describe --topic item-cadastrado --zookeeper zookeeper:2181 

#produce messages
#docker-compose exec kafka  bash -c "seq 100 | kafka-console-producer --request-required-acks 1 --broker-list zookeeper:9092 --topic item-cadastrado && echo 'Produced 100 messages.'"

# consume messages
# docker-compose exec kafka  kafka-console-consumer --bootstrap-server localhost:9092 --topic item-cadastrado --from-beginning --max-messages 100